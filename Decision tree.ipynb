{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af36450",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=pd.read_csv('compas-scores-two-years.csv')\n",
    "f1=f.loc[f['race'].isin(['African-American','Caucasian'])]\n",
    "f1.loc[f1['race'] == 'Caucasian', 'race'] = 0\n",
    "f1.loc[f1['race'] == 'African-American', 'race'] = 1\n",
    "f1.loc[f1['sex'] == 'Male', 'sex'] = 1\n",
    "f1.loc[f1['sex'] == 'Female', 'sex'] = 0\n",
    "f1=f1[['sex','age','race','juv_fel_count','priors_count.1','two_year_recid','score_text']]\n",
    "f1.loc[f1['score_text']=='Low', 'score_text'] = 0\n",
    "f1.loc[f1['score_text'] != 0, 'score_text'] = 1\n",
    "tr=f1[['sex','age','race','juv_fel_count','priors_count.1','two_year_recid']]\n",
    "tar=f1['score_text'].values\n",
    "tar=tar.astype('int')\n",
    "names=list(tr.columns)\n",
    "tr=tr.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c1765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train decision tree qnd export text\n",
    "decision_tree = DecisionTreeClassifier(random_state=0, max_depth=60)\n",
    "decision_tree = decision_tree.fit(tr, tar)\n",
    "r = export_text(decision_tree, feature_names=names,max_depth=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turns exported text to list of rules\n",
    "def make_positive_polynomial_and_dicts(text_rules, names=names):\n",
    "    r=text_rules\n",
    "    dt=[]\n",
    "    rules = r.splitlines()\n",
    "    currentrule=[]\n",
    "    for rule in rules:\n",
    "        depth = rule.count(\"|\")\n",
    "        rule=rule.split(\"--- \",1)[1]\n",
    "        if (depth<len(currentrule)):\n",
    "\n",
    "            dt.append(currentrule)\n",
    "            currentrule=currentrule[:depth-1]\n",
    "            currentrule.append(rule)\n",
    "            continue\n",
    "        currentrule.append(rule)\n",
    "    dt.append(currentrule)\n",
    "    \n",
    "    #turns dranching rules to binary variables, introducing one variable per rule\n",
    "    dict={}\n",
    "    i=1\n",
    "    for rule in dt:\n",
    "        for feat in rule:\n",
    "            if ((\">\" in feat) or (\"class\" in feat)):\n",
    "                continue\n",
    "            if (feat not in dict.values()):\n",
    "                    dict[\"x\"+str(i)]=feat\n",
    "                    i=i+1\n",
    "    dict1=dict\n",
    "    dict={v: k for k, v in dict.items()}\n",
    "    \n",
    "    #rewrites decision tree internal rules in terms of the new binary variables\n",
    "    boolrules=[]\n",
    "    temp=[]\n",
    "    for rule in dt:\n",
    "        for feat in rule:\n",
    "            if \">\" in feat:\n",
    "                terms=feat.split(\">\",1)\n",
    "                val=[value for key, value in dict.items() if terms[0].strip() in key and terms[1].strip() == key.split(' ')[-1]][0]\n",
    "                temp.append(str(val)+\"=0\")\n",
    "            elif \"<=\" in feat:\n",
    "                val=dict[feat]\n",
    "                temp.append(str(val)+\"=1\")\n",
    "            else:\n",
    "                temp.append(feat)\n",
    "        boolrules.append(temp)\n",
    "        temp=[]\n",
    "        \n",
    "        #construct positive and negative polynomials (as rules)\n",
    "    positiverules=[]\n",
    "    negrules=[]\n",
    "    for rule in boolrules:\n",
    "        if (rule[-1]==\"class: 1\"):\n",
    "            positiverules.append(rule[:-1])\n",
    "        else:\n",
    "            negrules.append(rule[:-1])\n",
    "            \n",
    "    #construct dictionary that maps the original variables to the features involving them, as well as the binary variables they correspond to\n",
    "    featurenames=names\n",
    "    d= dict.items()\n",
    "    newdict={}\n",
    "    for feat in featurenames:\n",
    "        keys = [(float(key.split(\" \")[-1]),val) for key,val in d if feat in key]\n",
    "        newdict[feat]= keys\n",
    "        \n",
    "    return positiverules, dict, dict1, newdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058f6598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import solver\n",
    "from ortools.linear_solver import pywraplp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714804a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the actual binary variables\n",
    "def make_variables(dict, solver):\n",
    "    variables=[]\n",
    "    for var in dict.values():\n",
    "        variables.append(solver.IntVar(0.0, 1.0, var))\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef2d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_names is a list of lists with the new categorical names, in the form X_1, X_2...\n",
    "def add_categorical_constraints(variables, cat_names, dict1, solver):\n",
    "\n",
    "    for cat_vars in cat_names:\n",
    "        sum=0\n",
    "        for var in cat_vars:\n",
    "            bool_var=[key for key,val in dict1.items() if var in val][0]\n",
    "            index = int(''.join(filter(str.isdigit, bool_var))) -1\n",
    "            sum=sum + variables[index]\n",
    "        solver.Add(sum==len(cat_vars)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct the left hand side of the constraints, assuming we use the positive polynomial\n",
    "def add_constraints(positiverules,variables, counter_outcome, solver):\n",
    "    constrs=[]\n",
    "    num=0\n",
    "    for rule in positiverules:\n",
    "        sum=0\n",
    "        for feat in rule:\n",
    "            if (feat[-1]==\"0\"):\n",
    "                sum=sum + 1-variables[int(''.join(filter(str.isdigit, feat.split('=',1)[0])))-1] \n",
    "            else:                                     \n",
    "                sum=sum + variables[int(''.join(filter(str.isdigit, feat.split('=',1)[0])))-1]  \n",
    "            num=num+1                                 \n",
    "        constrs.append((sum,num))\n",
    "        num=0\n",
    "        \n",
    "    if (counter_outcome==0):\n",
    "        #add constraints to enforce negative outcome, using the positive polynomial (so all positive rules must be zero)\n",
    "        for const in constrs:\n",
    "            solver.Add(const[0] <= const[1]-1)\n",
    "    elif(counter_outcome==1):\n",
    "        #alternatively, these constraints enforce positive outcome (having the positive polynomial equal 1)\n",
    "        sum=0\n",
    "        for const in constrs:\n",
    "            delta=solver.IntVar(0.0, 1.0, 'delta')\n",
    "            solver.Add(const[0] >= delta*const[1])\n",
    "            sum=sum+delta\n",
    "        solver.Add(sum==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29caf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diversity constraints\n",
    "#the 3 first are list of tuples: (feat, _constraint value)\n",
    "#must have initialized the optimization problem and all dicts and remaining constraints. This is the last step before solving!\n",
    "def diverse_counterfactual_constraints(eq_constrs, leq_constrs, gr_constrs,solver, newdict, variables):\n",
    "    for constr in eq_constrs:\n",
    "        feat, constr_val = constr\n",
    "        feats = newdict[feat]\n",
    "        for val, var in feats:\n",
    "            index= int(''.join(filter(str.isdigit, var))) -1\n",
    "            if (constr_val<= val):\n",
    "                solver.Add(variables[index] ==1)\n",
    "            else:\n",
    "                solver.Add(variables[index] ==0)\n",
    "                \n",
    "    for constr in leq_constrs:\n",
    "        feat, constr_val = constr\n",
    "        feats = newdict[feat]\n",
    "        for val, var in feats:\n",
    "            index= int(''.join(filter(str.isdigit, var))) -1\n",
    "            if (constr_val<= val):\n",
    "                solver.Add(variables[index] ==1)\n",
    "                \n",
    "    for constr in gr_constrs:\n",
    "        feat, constr_val = constr\n",
    "        feats = newdict[feat]\n",
    "        for val, var in feats:\n",
    "            index= int(''.join(filter(str.isdigit, var))) -1\n",
    "            if (constr_val > val):\n",
    "                solver.Add(variables[index] ==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2761611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this computes the transformed data point\n",
    "\n",
    "def make_actual_datapoint(datapoint, dict, newdict, featurenames):\n",
    "    new_datapoint=np.zeros(len(dict))\n",
    "    new_datapoint_indices=np.zeros(len(dict))\n",
    "    sum=0 \n",
    "    i=0\n",
    "    j=0\n",
    "    for feat in featurenames:\n",
    "        current_tree_features=newdict[feat]\n",
    "        for rules in current_tree_features:\n",
    "            index= int(''.join(filter(str.isdigit, rules[1]))) -1\n",
    "            new_datapoint_indices[j]=index\n",
    "            cond= rules[0]\n",
    "            if (datapoint[i]<= cond):\n",
    "                new_datapoint[j]=1\n",
    "            else:\n",
    "                new_datapoint[j]=0\n",
    "            j=j+1\n",
    "        i=i+1\n",
    "    return new_datapoint, new_datapoint_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b8ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this computes the standard deviation of binary features\n",
    "def make_coefficients(tr, new_datapoint, featurenames, newdict):\n",
    "    sum=0\n",
    "    i=0\n",
    "    binary=np.zeros(len(new_datapoint))\n",
    "    j=0\n",
    "    for feat in featurenames:\n",
    "        current_tree_features=newdict[feat]\n",
    "        for rules in current_tree_features:\n",
    "            index= int(''.join(filter(str.isdigit, rules[1]))) -1\n",
    "            cond= rules[0]\n",
    "            masked_data= tr[:,i]   # dataset[:,i]\n",
    "            n=len(masked_data)\n",
    "            masked_data=masked_data[masked_data<=cond]\n",
    "            p=len(masked_data)\n",
    "            p=p/n\n",
    "            variance=p*(1-p)\n",
    "            binary[j]=np.sqrt(variance)\n",
    "            j=j+1\n",
    "        i=i+1\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9abb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct the objective function\n",
    "def make_objective(actualdatapoint, coeff, variables, new_datapoint_indices, solver):\n",
    "    obj=0\n",
    "    index=0\n",
    "    for feat in actualdatapoint:\n",
    "        if feat==0:\n",
    "            obj=obj+coeff[index]*variables[int(new_datapoint_indices[index])]\n",
    "        else:\n",
    "            obj=obj+coeff[index]*(1-variables[int(new_datapoint_indices[index])])\n",
    "        index=index+1\n",
    "    solver.Minimize(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb7a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def written_counterfactual(variables, new_datapoint, new_datapoint_indices, dict1):\n",
    "    solution=[]\n",
    "    for var in variables:\n",
    "            solution.append(var.solution_value())\n",
    "\n",
    "    counter_changes=[]\n",
    "    counter_indices=np.where(new_datapoint[np.argsort(np.array(list(map(int,new_datapoint_indices))))]!=solution)[0]\n",
    "\n",
    "    for counter_index in counter_indices:\n",
    "        if solution[counter_index]==1:\n",
    "            counter_changes.append(dict1['x'+str(counter_index+1)])\n",
    "        elif solution[counter_index]==0:\n",
    "            counter_changes.append(dict1['x'+str(counter_index+1)].replace('<=','>'))\n",
    "\n",
    "    ls= list(map(lambda x: x.split('<=')+['<='] if '<=' in x  else x.split('>')+['>'], counter_changes))\n",
    "    from collections import defaultdict\n",
    "    d = defaultdict(list)\n",
    "\n",
    "    for k, *v in ls:\n",
    "        d[k].append(v)\n",
    "\n",
    "    bn=list(d.items())\n",
    "    grouped=[]\n",
    "    for p, r in bn:\n",
    "        greater=[]\n",
    "        lower=[]\n",
    "        for k, v in r:\n",
    "            if (v=='<='):\n",
    "                lower.append(k)\n",
    "            elif (v=='>'):\n",
    "                greater.append(k)\n",
    "        lower=['<=']+lower\n",
    "        greater=['>']+greater\n",
    "        grouped.append([p,lower,greater])\n",
    "    written_counterfactuals=[]\n",
    "    for feature,lower,greater in grouped:\n",
    "        s=feature\n",
    "        if(len(lower)>1):\n",
    "            u_bound=min(map(float,lower[1:]))\n",
    "            s=s+ '<= '+ str(u_bound)\n",
    "        if(len(greater)>1):\n",
    "            l_bound=max(map(float,greater[1:]))\n",
    "            s= str(l_bound) + ' < ' +s\n",
    "        written_counterfactuals.append(s)\n",
    "    return written_counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9408a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(90)\n",
    "K=5\n",
    "indices = random.sample(range(len(tr)), K)\n",
    "exp_data=[tr[i] for i in sorted(indices)]\n",
    "exp_tar=[decision_tree.predict(exp_data[i].reshape(1, -1)) for i in range(len(exp_data))]\n",
    "\n",
    "positiverules, feat_to_bool, bool_to_feat, var_to_feats_and_bools = make_positive_polynomial_and_dicts(r)\n",
    "\n",
    "\n",
    "counterfactuals=[]\n",
    "\n",
    "for i in range(K):\n",
    "    datapoint = exp_data[i]\n",
    "    counter_outcome = 0 if exp_tar[i] == 1 else 1\n",
    "    \n",
    "    #initialize solver\n",
    "    solver = pywraplp.Solver.CreateSolver('SCIP')\n",
    "    variables = make_variables(feat_to_bool, solver)\n",
    "    \n",
    "    add_constraints(positiverules,variables, counter_outcome, solver)\n",
    "    new_datapoint, new_datapoint_indices = make_actual_datapoint(datapoint, feat_to_bool, var_to_feats_and_bools, names)\n",
    "    coeff = make_coefficients(tr, new_datapoint, names, var_to_feats_and_bools)\n",
    "    make_objective(new_datapoint, coeff, variables, new_datapoint_indices, solver)\n",
    "    status = solver.Solve()\n",
    "    cntr=written_counterfactual(variables, new_datapoint, new_datapoint_indices, bool_to_feat)\n",
    "    counterfactuals.append(cntr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
