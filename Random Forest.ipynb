{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b67bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSAT dataset\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "import six.moves.urllib as urllib\n",
    "import pprint\n",
    "_DATA_ROOT = tempfile.mkdtemp(prefix='lsat-data')\n",
    "_DATA_PATH = 'https://storage.googleapis.com/lawschool_dataset/bar_pass_prediction.csv'\n",
    "_DATA_FILEPATH = os.path.join(_DATA_ROOT, 'bar_pass_prediction.csv')\n",
    "\n",
    "data = urllib.request.urlopen(_DATA_PATH)\n",
    "\n",
    "_LSAT_DF = pd.read_csv(data)\n",
    "\n",
    "# To simpliy the case study, we will only use the columns that will be used for\n",
    "# our model.\n",
    "_COLUMN_NAMES = [\n",
    "  'gender',\n",
    "  'lsat',\n",
    "  'pass_bar',\n",
    "  'race1',\n",
    "  'ugpa',\n",
    "]\n",
    "\n",
    "_LSAT_DF.dropna()\n",
    "_LSAT_DF['gender'] = _LSAT_DF['gender'].astype(str)\n",
    "_LSAT_DF['race1'] = _LSAT_DF['race1'].astype(str)\n",
    "_LSAT_DF = _LSAT_DF[_COLUMN_NAMES]\n",
    "\n",
    "_LSAT_DF= _LSAT_DF=_LSAT_DF[_LSAT_DF['gender']!='nan']\n",
    "_LSAT_DF=_LSAT_DF[_LSAT_DF['race1']!='other']\n",
    "_LSAT_DF=_LSAT_DF[_LSAT_DF['race1']!='nan']\n",
    "\n",
    "_LSAT_DF['race1'][_LSAT_DF['race1']=='white']=1\n",
    "_LSAT_DF['race1'][_LSAT_DF['race1']=='hisp']=2\n",
    "_LSAT_DF['race1'][_LSAT_DF['race1']=='asian']=3\n",
    "_LSAT_DF['race1'][_LSAT_DF['race1']=='black']=4\n",
    "\n",
    "_LSAT_DF['gender'][_LSAT_DF['gender']=='male']=1\n",
    "_LSAT_DF['gender'][_LSAT_DF['gender']=='female']=0\n",
    "\n",
    "tr=_LSAT_DF[['gender','lsat','race1','ugpa']]\n",
    "tar=_LSAT_DF['pass_bar'].values\n",
    "\n",
    "\n",
    "tar=tar.astype('int')\n",
    "tr, cat_names=to_binary(tr,['race1'],[4])\n",
    "names=list(tr.columns)\n",
    "tr=tr.values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7833ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify dataset turning categorical to binary variables\n",
    "\n",
    "def to_binary(dataset, categorical_vars, num_of_categories):\n",
    "    new_vars=[]\n",
    "    for var,cat in zip(categorical_vars, num_of_categories):\n",
    "        temp=[]\n",
    "        for c in range(cat):\n",
    "            dataset[var+'_'+str(c+1)]=0\n",
    "            dataset.loc[dataset[var] == c+1, var+'_'+str(c+1)] = 1\n",
    "            temp.append(var+'_'+str(c+1))\n",
    "        new_vars.append(temp)\n",
    "        dataset = dataset.drop(var, 1)\n",
    "    return dataset, new_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train random forests and export texts; for example\n",
    "rf = RandomForestClassifier(random_state=0, n_estimators=5, max_depth= 100)\n",
    "rf = rf.fit(tr, tar)\n",
    "\n",
    "textdt=[]\n",
    "\n",
    "for dt in rf.estimators_:\n",
    "    textdt.append(export_text(dt, feature_names=names,max_depth=1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec4212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for predicting based onmajority voting\n",
    "def prediction(rf,datapoint):\n",
    "    ones=0\n",
    "    zeros=0\n",
    "    for dt in rf.estimators_:\n",
    "        if (dt.predict(datapoint.reshape(1, -1))==1):\n",
    "            ones=ones+1\n",
    "        elif (dt.predict(datapoint.reshape(1, -1))==0):\n",
    "            zeros=zeros+1\n",
    "    if (ones<zeros):\n",
    "        return 0\n",
    "    elif (ones>=zeros):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebf8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "variablenames=list(string.ascii_lowercase)[:len(textdt)]\n",
    "treecount=0\n",
    "treerules=[]\n",
    "tree_feature_to_boolean=[]\n",
    "tree_variable_to_boolean_and_feature=[]\n",
    "tree_polynomials=[]\n",
    "listofvariables=[]\n",
    "\n",
    "\n",
    "boolean_rules=[]\n",
    "boolean_to_tree_feature=[]\n",
    "list_of_rules=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56300072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for making the positive decision polynomial\n",
    "def make_positive_polynomial_and_dicts(textdt, names=names): \n",
    "    #for eah tree turns exported text to list of rules\n",
    "    list_of_rules=[]\n",
    "    boolean_to_tree_feature=[] \n",
    "    boolean_rules=[]\n",
    "    tree_polynomials=[] \n",
    "    tree_variable_to_boolean_and_feature=[]\n",
    "    tree_feature_to_boolean=[]  \n",
    "    i=1\n",
    "    for r in textdt:\n",
    "        dt=[]\n",
    "        rules = r.splitlines()\n",
    "        currentrule=[]\n",
    "        for rule in rules:\n",
    "            depth = rule.count(\"|\")\n",
    "            rule=rule.split(\"--- \",1)[1]\n",
    "            if (depth<len(currentrule)):\n",
    "\n",
    "                dt.append(currentrule)\n",
    "                currentrule=currentrule[:depth-1]\n",
    "                currentrule.append(rule)\n",
    "                continue\n",
    "            currentrule.append(rule)\n",
    "        dt.append(currentrule)\n",
    "\n",
    "        list_of_rules.append(dt)\n",
    "\n",
    "    #turns dranching rules to binary variables, introducing one variable per rule\n",
    "        dict={}\n",
    "        dict1={}\n",
    "\n",
    "        for rule in dt:\n",
    "            for feat in rule:\n",
    "                if ((\">\" in feat) or (\"class\" in feat)):\n",
    "                    continue\n",
    "                if (feat not in dict.values()):\n",
    "                    if ([True for pr_dict in boolean_to_tree_feature if feat in pr_dict.values()]==[]):\n",
    "                        dict[\"x\"+str(i)]=feat             \n",
    "                        i=i+1\n",
    "        dict1=dict\n",
    "        dict={v: k for k, v in dict.items()}\n",
    "\n",
    "        tree_feature_to_boolean.append(dict) \n",
    "        boolean_to_tree_feature.append(dict1)\n",
    "\n",
    "    #rewrites decision tree internal rules in terms of the new binary variables\n",
    "        boolrules=[]\n",
    "        temp=[]\n",
    "        for rule in dt:\n",
    "            for feat in rule:\n",
    "                if \">\" in feat:\n",
    "                    terms=feat.split(\">\",1)\n",
    "                    \n",
    "                    val=[value for key, value in dict.items() if terms[0].strip() in key and terms[1].strip() == key.split(' ')[-1]]\n",
    "                    if (val==[]):\n",
    "                        val=[value for pr_dict in tree_feature_to_boolean for key, value in pr_dict.items() if terms[0].strip() in key and terms[1].strip() == key.split(' ')[-1]]\n",
    "                    val=val[0]   \n",
    "                    temp.append(str(val)+\"=0\")\n",
    "                elif \"<=\" in feat:\n",
    "                    try:\n",
    "                        val=dict[feat]\n",
    "                    except:\n",
    "                        for pr_dict in tree_feature_to_boolean:   #mine new\n",
    "                            if (feat in pr_dict.keys()):\n",
    "                                val=pr_dict[feat]\n",
    "                                break\n",
    "                    temp.append(str(val)+\"=1\")\n",
    "                else:\n",
    "                    temp.append(feat)\n",
    "            boolrules.append(temp)\n",
    "            temp=[]\n",
    "\n",
    "        boolean_rules.append(boolrules)\n",
    "        #construct positive and negative polynomials (as rules)\n",
    "        positiverules=[]\n",
    "        negrules=[]\n",
    "        for rule in boolrules:\n",
    "            if (rule[-1]==\"class: 1.0\"):\n",
    "                positiverules.append(rule[:-1])\n",
    "            else:\n",
    "                negrules.append(rule[:-1])\n",
    "        tree_polynomials.append((positiverules,negrules)) \n",
    "\n",
    "    #construct dictionary that maps the original variables to the features involving them, as well as the binary variables they correspond to\n",
    "        featurenames=names\n",
    "        d= dict.items()\n",
    "        newdict={}\n",
    "        for feat in featurenames:\n",
    "            keys = [(float(key.split(\" \")[-1]),val) for key,val in d if feat in key]\n",
    "            newdict[feat]= keys\n",
    "\n",
    "        tree_variable_to_boolean_and_feature.append(newdict)\n",
    "        \n",
    "\n",
    "    newdict={}  \n",
    "    for feat in featurenames:\n",
    "        newdict[feat]=[]\n",
    "        for pr_dict in tree_variable_to_boolean_and_feature:\n",
    "            newdict[feat]=newdict[feat]+pr_dict[feat]\n",
    "\n",
    "    return boolean_to_tree_feature, tree_polynomials, tree_feature_to_boolean, newdict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d259373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import solver\n",
    "from ortools.linear_solver import pywraplp\n",
    "#initialize solver\n",
    "solver = pywraplp.Solver.CreateSolver('SCIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_variables_and_constraints(tree_feature_to_boolean, tree_polynomials, counter_outcome, solver):\n",
    "    import math \n",
    "   \n",
    "    deltasum=0\n",
    "    listofvariables=[] \n",
    "    for tree in range(len(tree_polynomials)):\n",
    "\n",
    "    #create the actual binary variables\n",
    "        variables=[]\n",
    "        for var in tree_feature_to_boolean[tree].values(): \n",
    "            listofvariables.append(solver.IntVar(0.0, 1.0, var)) \n",
    "\n",
    "    #construct the left hand side of the constraints, assuming we use the positive polynomial\n",
    "        constrs=[]\n",
    "        num=0\n",
    "        for rule in tree_polynomials[tree][0]: \n",
    "            sum=0\n",
    "            for feat in rule:\n",
    "                \n",
    "                if (feat[-1]==\"0\"):\n",
    "                    sum=sum + 1-listofvariables[int(''.join(filter(str.isdigit, feat.split('=',1)[0])))-1] \n",
    "                else:                                     \n",
    "                    sum=sum + listofvariables[int(''.join(filter(str.isdigit, feat.split('=',1)[0])))-1]  \n",
    "                num=num+1                                 \n",
    "            constrs.append((sum,num))\n",
    "            num=0\n",
    "        if(counter_outcome==0):\n",
    "        #add constraints to enforce negative outcome, using the positive polynomial (so all positive rules must be zero)\n",
    "            sum=0\n",
    "            delta=solver.IntVar(0.0, 1.0, 'delta')\n",
    "            for const in constrs:\n",
    "                solver.Add(const[0] - const[1] <= delta -1)\n",
    "            deltasum=deltasum+delta\n",
    "        elif(counter_outcome==1):\n",
    "    #alternatively, these constraints enforce positive outcome (using the new result, having the positive polynomial equal 1)\n",
    "\n",
    "            sum=0\n",
    "            for const in constrs:\n",
    "                delta=solver.IntVar(0.0, 1.0, 'delta')\n",
    "                solver.Add(const[0] >= delta*const[1])\n",
    "                sum=sum+delta\n",
    "            deltaprime=solver.IntVar(0.0, 1.0, 'Delta') \n",
    "            deltasum=deltasum + deltaprime\n",
    "            solver.Add(sum==deltaprime)\n",
    "\n",
    "    \n",
    "    if (counter_outcome==0):\n",
    "        solver.Add(deltasum<=int(math.ceil(len(textdt)/2))-1)\n",
    "    elif(counter_outcome==1):\n",
    "        solver.Add(deltasum>=int(math.ceil(len(textdt)/2)))  \n",
    "\n",
    "    return listofvariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0969f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_names is a list of lists with the new categorical names, in the form X_1, X_2...\n",
    "def add_categorical_constraints(variables, cat_names, dict1, solver):\n",
    "\n",
    "    for cat_vars in cat_names:\n",
    "        sum=0\n",
    "        i=0\n",
    "        for var in cat_vars:\n",
    "            bool_vars=[val for key,val in dict1.items() if var in key]\n",
    "            for feats in bool_vars:\n",
    "                index = int(''.join(filter(str.isdigit, feats[0][1]))) -1\n",
    "                sum=sum + variables[index]\n",
    "                i=i+1\n",
    "        solver.Add(sum==i-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8334ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diversity constraints\n",
    "#the 3 first are list of tuples: (feat, _constraint value)\n",
    "#must have initialized the optimization problem and all dicts and remaining constraints. This is the last step before solving!\n",
    "def diverse_counterfactual_constraints(eq_constrs, leq_constrs, gr_constrs,solver, newdict, variables):\n",
    "    for constr in eq_constrs:\n",
    "        feat, constr_val = constr\n",
    "        feats = newdict[feat]\n",
    "        for val, var in feats:\n",
    "            index= int(''.join(filter(str.isdigit, var))) -1\n",
    "            if (constr_val<= val):\n",
    "                solver.Add(variables[index] ==1)\n",
    "            else:\n",
    "                solver.Add(variables[index] ==0)\n",
    "                \n",
    "    for constr in leq_constrs:\n",
    "        feat, constr_val = constr\n",
    "        feats = newdict[feat]\n",
    "        for val, var in feats:\n",
    "            index= int(''.join(filter(str.isdigit, var))) -1\n",
    "            if (constr_val<= val):\n",
    "                solver.Add(variables[index] ==1)\n",
    "                \n",
    "    for constr in gr_constrs:\n",
    "        feat, constr_val = constr\n",
    "        feats = newdict[feat]\n",
    "        for val, var in feats:\n",
    "            index= int(''.join(filter(str.isdigit, var))) -1\n",
    "            if (constr_val > val):\n",
    "                solver.Add(variables[index] ==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c06e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this computes the transformed data point\n",
    "\n",
    "def make_actual_datapoint(datapoint, newdict, featurenames):\n",
    "    num_of_feats=np.sum([len(value) for value in newdict.values()])\n",
    "    new_datapoint=np.zeros(num_of_feats)\n",
    "    new_datapoint_indices=np.zeros(num_of_feats)\n",
    "    sum=0 \n",
    "    mini_sum=0\n",
    "    i=0\n",
    "    j=0\n",
    "    for feat in featurenames:\n",
    "        current_tree_features=newdict[feat]\n",
    "        for rules in current_tree_features:\n",
    "            index= int(''.join(filter(str.isdigit, rules[1]))) -1\n",
    "            new_datapoint_indices[j]=index\n",
    "            cond= rules[0]\n",
    "            if (datapoint[i]<= cond):\n",
    "                new_datapoint[j]=1\n",
    "            else:\n",
    "                new_datapoint[j]=0\n",
    "            j=j+1\n",
    "        i=i+1\n",
    "    return new_datapoint, new_datapoint_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c2b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes standard deviation\n",
    "def make_coefficients(tr, new_datapoint, featurenames, newdict):\n",
    "    sum=0\n",
    "    i=0\n",
    "    mini_sum=0\n",
    "    binary=np.zeros(len(new_datapoint))\n",
    "    j=0\n",
    "    for feat in featurenames:\n",
    "        current_tree_features=newdict[feat]\n",
    "        for rules in current_tree_features:\n",
    "            index= int(''.join(filter(str.isdigit, rules[1]))) -1\n",
    "            cond= rules[0]\n",
    "            masked_data= tr[:,i]   # dataset[:,i]\n",
    "            n=len(masked_data)\n",
    "            masked_data=masked_data[masked_data<=cond]\n",
    "            p=len(masked_data)\n",
    "            p=p/n\n",
    "            variance=p*(1-p)\n",
    "            binary[j]=np.sqrt(variance)\n",
    "            j=j+1\n",
    "        i=i+1\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa1dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct the objective function\n",
    "def make_objective(actualdatapoint, coeff, listofvariables, new_datapoint_indices, solver):\n",
    "    obj=0\n",
    "    index=0\n",
    "    for feat in actualdatapoint:\n",
    "        if feat==0:\n",
    "            obj=obj+coeff[index]*listofvariables[int(new_datapoint_indices[index])]\n",
    "        else:\n",
    "            obj=obj+coeff[index]*(1-listofvariables[int(new_datapoint_indices[index])])\n",
    "        index=index+1\n",
    "    solver.Minimize(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def written_counterfactual(listofvariables, new_datapoint, new_datapoint_indices, boolean_to_tree_feature):\n",
    "    dict1 = {}\n",
    "    for dictionary in boolean_to_tree_feature:\n",
    "        dict1.update(dictionary)\n",
    "\n",
    "    solution=[]\n",
    "    for var in listofvariables:\n",
    "            solution.append(var.solution_value())\n",
    "\n",
    "    counter_changes=[]\n",
    "    counter_indices=np.where(new_datapoint[np.argsort(np.array(list(map(int,new_datapoint_indices))))]!=solution)[0]\n",
    "\n",
    "    for counter_index in counter_indices:\n",
    "        if solution[counter_index]==1:\n",
    "            counter_changes.append(dict1['x'+str(counter_index+1)])\n",
    "        elif solution[counter_index]==0:\n",
    "            counter_changes.append(dict1['x'+str(counter_index+1)].replace('<=','>'))\n",
    "\n",
    "    ls= list(map(lambda x: x.split('<=')+['<='] if '<=' in x  else x.split('>')+['>'], counter_changes))\n",
    "    from collections import defaultdict\n",
    "    d = defaultdict(list)\n",
    "\n",
    "    for k, *v in ls:\n",
    "        d[k].append(v)\n",
    "\n",
    "    bn=list(d.items())\n",
    "    grouped=[]\n",
    "    for p, r in bn:\n",
    "        greater=[]\n",
    "        lower=[]\n",
    "        for k, v in r:\n",
    "            if (v=='<='):\n",
    "                lower.append(k)\n",
    "            elif (v=='>'):\n",
    "                greater.append(k)\n",
    "        lower=['<=']+lower\n",
    "        greater=['>']+greater\n",
    "        grouped.append([p,lower,greater])\n",
    "    written_counterfactuals=[]\n",
    "    for feature,lower,greater in grouped:\n",
    "        s=feature\n",
    "        if(len(lower)>1):\n",
    "            u_bound=min(map(float,lower[1:]))\n",
    "            s=s+ '<= '+ str(u_bound)\n",
    "        if(len(greater)>1):\n",
    "            l_bound=max(map(float,greater[1:]))\n",
    "            s= str(l_bound) + ' < ' +s\n",
    "        written_counterfactuals.append(s)\n",
    "    return written_counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa98903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "K=5\n",
    "random.seed(101)\n",
    "indices = random.sample(range(len(tr)), K)\n",
    "exp_data=[tr[i] for i in sorted(indices)]\n",
    "exp_tar=[prediction(rf, exp_data[i]) for i in range(len(exp_data))]\n",
    "\n",
    "boolean_to_tree_feature, tree_polynomials, tree_feature_to_boolean, newdict = make_positive_polynomial_and_dicts(textdt)\n",
    "\n",
    "counterfactuals=[]\n",
    "\n",
    "for i in range(K):\n",
    "    datapoint = exp_data[i]\n",
    "    counter_outcome = 0 if exp_tar[i] == 1 else 1\n",
    "    \n",
    "    #initialize solver\n",
    "    solver = pywraplp.Solver.CreateSolver('SCIP')\n",
    "    \n",
    "    variables=make_variables_and_constraints(tree_feature_to_boolean, tree_polynomials, counter_outcome, solver)\n",
    "    \n",
    "    if (i==0):\n",
    "        diverse_counterfactual_constraints([('race1_1',1)], [], [],solver, newdict, variables)\n",
    "    elif(i==1):\n",
    "        diverse_counterfactual_constraints([],[], [('lsat',30)],solver, newdict, variables)\n",
    "    elif(i==2):\n",
    "        diverse_counterfactual_constraints([('race1_1',1)], [], [],solver, newdict, variables)\n",
    "    elif(i==3):\n",
    "        diverse_counterfactual_constraints([],[], [('lsat',25)],solver, newdict, variables)\n",
    "    else:\n",
    "        diverse_counterfactual_constraints([('race1_1',1)], [], [],solver, newdict, variables)\n",
    "    \n",
    "    #add_constraints(positiverules,variables, counter_outcome, solver)\n",
    "    add_categorical_constraints(variables, [['race1_1','race1_2','race1_3','race1_4']], newdict, solver)\n",
    "    new_datapoint, new_datapoint_indices = make_actual_datapoint(datapoint, newdict, names)\n",
    "    coeff = make_coefficients(tr, new_datapoint, names, newdict)\n",
    "    make_objective(new_datapoint, coeff, variables, new_datapoint_indices, solver)\n",
    "    status = solver.Solve()\n",
    "    cntr=written_counterfactual(variables, new_datapoint, new_datapoint_indices, boolean_to_tree_feature)\n",
    "    counterfactuals.append(cntr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
